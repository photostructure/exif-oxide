# Modular Codegen Makefile
# This demonstrates the updated build system for parallel execution

.PHONY: all clean extract-perl generate-rust codegen parallel-extract patch-exiftool revert-exiftool-patches check-schemas

# Output directories
GENERATED_DIR := generated
EXTRACT_DIR := $(GENERATED_DIR)/extract

# Perl extractor outputs
TAG_TABLES_JSON := $(GENERATED_DIR)/tag_tables.json
COMPOSITE_TAGS_JSON := $(GENERATED_DIR)/composite_tags.json
REGEX_PATTERNS_JSON := $(GENERATED_DIR)/regex_patterns.json
FILE_TYPE_LOOKUP_JSON := $(GENERATED_DIR)/file_type_lookup.json

# Individual extractors can run in parallel
EXTRACTOR_OUTPUTS := \
	$(TAG_TABLES_JSON) \
	$(COMPOSITE_TAGS_JSON) \
	$(REGEX_PATTERNS_JSON) \
	$(FILE_TYPE_LOOKUP_JSON)

# Extract data to individual files
EXTRACT_FILES := \
	$(EXTRACT_DIR)/canon_model_id.json \
	$(EXTRACT_DIR)/nikon_lens_ids.json \
	$(EXTRACT_DIR)/canon_white_balance.json \
	$(EXTRACT_DIR)/orientation.json

# Default target
all: codegen

# Main codegen pipeline
codegen: check-schemas generate-rust
	@$(MAKE) -f Makefile.modular revert-exiftool-patches
	@echo "✅ Code generation complete!"

# Create directories
$(GENERATED_DIR) $(EXTRACT_DIR):
	@mkdir -p $@

# Patch ExifTool modules to expose my-scoped variables
patch-exiftool:
	@echo "🔧 Patching ExifTool modules to expose variables..."
	@eval $$(perl -I ~/perl5/lib/perl5/ -Mlocal::lib) && perl patch_exiftool_modules.pl
	@echo "✅ ExifTool modules patched"

# Revert ExifTool module patches to keep submodule clean
revert-exiftool-patches:
	@echo "🔄 Reverting ExifTool module patches..."
	@git -C ../third-party/exiftool checkout -- lib/Image/*.pm lib/Image/ExifTool/*.pm
	@echo "✅ ExifTool modules reverted to original state"

# Parallel extraction of all Perl data
extract-perl: patch-exiftool $(GENERATED_DIR) $(EXTRACT_DIR) parallel-extract extract-data
	@echo "✅ All extraction complete"

# Run extractors in parallel (make -j4 will use 4 cores)
parallel-extract: $(EXTRACTOR_OUTPUTS)

# Individual extractor rules (simplified - only use extractors that don't depend on extract.json)
$(TAG_TABLES_JSON): extractors/tag_tables.pl
	@echo "📋 Extracting EXIF/GPS tags..."
	@eval $$(perl -I ~/perl5/lib/perl5/ -Mlocal::lib) && perl $< > $@

$(COMPOSITE_TAGS_JSON): extractors/composite_tags.pl
	@echo "🔗 Extracting composite tags..."
	@eval $$(perl -I ~/perl5/lib/perl5/ -Mlocal::lib) && perl $< > $@

# Note: regex_patterns.pl and file_type_lookup.pl disabled because they depend on extract.json
# Our simplified simple_table.pl handles these tables as simple lookups instead
$(REGEX_PATTERNS_JSON):
	@echo "🔍 Creating empty regex patterns file (handled by simplified extraction)..."
	@echo '{"extracted_at":"'$(shell date)'","patterns":{"file_extensions":[],"magic_numbers":[]},"compatibility_notes":"Handled by simplified simple_table.pl"}' > $@

$(FILE_TYPE_LOOKUP_JSON):
	@echo "📁 Creating empty file type lookup file (handled by simplified extraction)..."
	@echo '{"extracted_at":"'$(shell date)'","file_type_lookups":{"extensions":[],"mime_types":[],"descriptions":[],"magic_lookups":[]},"stats":{"total_lookups":0,"by_type":{}}}' > $@

# Extract data using the new simplified simple_table.pl
extract-data: $(EXTRACT_FILES)

$(EXTRACT_FILES): extractors/simple_table.pl config/Canon_pm/simple_table.json config/Nikon_pm/simple_table.json config/ExifTool_pm/simple_table.json config/Exif_pm/simple_table.json config/XMP_pm/simple_table.json
	@echo "📊 Extracting lookup tables from config..."
	@$(MAKE) -f Makefile.modular extract-canon extract-nikon extract-exiftool extract-exif extract-xmp
	@$(MAKE) -f Makefile.modular split-extractions
	@touch $(EXTRACT_FILES)  # Update timestamps

# Extract from each module using the simplified simple_table.pl
EXIFTOOL_LIB := ../third-party/exiftool/lib/Image/ExifTool

extract-canon:
	@echo "  📷 Canon tables..."
	@eval $$(perl -I ~/perl5/lib/perl5/ -Mlocal::lib) && perl extractors/simple_table.pl $(EXIFTOOL_LIB)/Canon.pm canonModelID canonWhiteBalance pictureStyles canonImageSize canonQuality > $(EXTRACT_DIR)/canon_combined.json

extract-nikon:
	@echo "  📷 Nikon tables..."
	@eval $$(perl -I ~/perl5/lib/perl5/ -Mlocal::lib) && perl extractors/simple_table.pl $(EXIFTOOL_LIB)/Nikon.pm nikonLensIDs > $(EXTRACT_DIR)/nikon_combined.json

extract-exiftool:
	@echo "  🔧 ExifTool core tables..."
	@eval $$(perl -I ~/perl5/lib/perl5/ -Mlocal::lib) && perl extractors/simple_table.pl $(EXIFTOOL_LIB).pm mimeType fileTypeExt magicNumber fileTypeLookup > $(EXTRACT_DIR)/exiftool_simple.json
	@eval $$(perl -I ~/perl5/lib/perl5/ -Mlocal::lib) && perl extractors/simple_table.pl $(EXIFTOOL_LIB).pm weakMagic > $(EXTRACT_DIR)/exiftool_boolean.json

extract-exif:
	@echo "  📸 EXIF tables..."
	@eval $$(perl -I ~/perl5/lib/perl5/ -Mlocal::lib) && perl extractors/simple_table.pl $(EXIFTOOL_LIB)/Exif.pm orientation > $(EXTRACT_DIR)/exif_combined.json

extract-xmp:
	@echo "  🏷️  XMP tables..."
	@eval $$(perl -I ~/perl5/lib/perl5/ -Mlocal::lib) && perl extractors/simple_table.pl $(EXIFTOOL_LIB)/XMP.pm nsURI xmpNS charName charNum stdXlatNS > $(EXTRACT_DIR)/xmp_combined.json

# Split combined extractions into individual files (for compatibility with existing system)
split-extractions:
	@echo "📄 Splitting combined extractions into individual files..."
	@cd $(EXTRACT_DIR) && \
	for combined in *_combined.json *_simple.json *_boolean.json; do \
		if [ -f "$$combined" ]; then \
			echo "  Processing $$combined..."; \
			eval $$(perl -I ~/perl5/lib/perl5/ -Mlocal::lib) && perl -MJSON -E 'local $$/; $$data = decode_json(<>); if (ref $$data eq "ARRAY") { for my $$i (0..$$#$$data) { $$item = $$data->[$$i]; $$hash = $$item->{source}{hash_name}; $$hash =~ s/^%//; say STDERR "    Creating $${hash}.json"; open my $$fh, ">", "$${hash}.json"; print $$fh encode_json($$item); close $$fh; } } else { $$hash = $$data->{source}{hash_name}; $$hash =~ s/^%//; say STDERR "    Creating $${hash}.json"; open my $$fh, ">", "$${hash}.json"; print $$fh encode_json($$data); close $$fh; }' < "$$combined"; \
		fi; \
	done

# Rust code generation
generate-rust: extract-perl
	@echo "🦀 Generating Rust code..."
	@cd . && cargo run --release

# Clean generated files
clean:
	@echo "🧹 Cleaning generated files..."
	@rm -f $(EXTRACTOR_OUTPUTS)
	@rm -f $(EXTRACT_DIR)/*.json
	@rm -rf ../src/generated/*

# Individual cleaning targets
clean-tags:
	@rm -f $(TAG_TABLES_JSON)

clean-extract:
	@rm -f $(EXTRACT_DIR)/*.json

# Incremental regeneration targets
regen-tags: clean-tags $(TAG_TABLES_JSON) generate-rust

regen-extract: clean-extract extract-data generate-rust

# Development helpers
check-schemas:
	@echo "🔍 Validating configuration schemas..."
	@cargo run --release 2>/dev/null | grep -q "Schema validation" || echo "Note: Schema validation via Rust code generation"

check-extractors:
	@echo "Checking Perl extractor syntax..."
	@eval $$(perl -I ~/perl5/lib/perl5/ -Mlocal::lib) && perl -c extractors/tag_tables.pl
	@eval $$(perl -I ~/perl5/lib/perl5/ -Mlocal::lib) && perl -c extractors/composite_tags.pl
	@eval $$(perl -I ~/perl5/lib/perl5/ -Mlocal::lib) && perl -c extractors/regex_patterns.pl
	@eval $$(perl -I ~/perl5/lib/perl5/ -Mlocal::lib) && perl -c extractors/file_type_lookup.pl
	@eval $$(perl -I ~/perl5/lib/perl5/ -Mlocal::lib) && perl -c extractors/simple_table.pl

# Show what would be built
dry-run:
	@$(MAKE) -n codegen

# Parallel execution example
parallel-demo:
	@echo "Running parallel extraction with 4 jobs..."
	@$(MAKE) -j4 parallel-extract

# Help target
help:
	@echo "Modular Codegen Makefile"
	@echo "======================="
	@echo ""
	@echo "Targets:"
	@echo "  make              - Run full codegen pipeline"
	@echo "  make -j4          - Run with 4 parallel jobs"
	@echo "  make clean        - Clean all generated files"
	@echo "  make regen-tags   - Regenerate only tag tables"
	@echo "  make parallel-demo - Demo parallel extraction"
	@echo ""
	@echo "Individual extractors:"
	@echo "  make $(TAG_TABLES_JSON)"
	@echo "  make $(COMPOSITE_TAGS_JSON)"
	@echo "  make extract-data"
	@echo ""
	@echo "The modular design allows:"
	@echo "  - Parallel execution of extractors"
	@echo "  - Incremental regeneration"
	@echo "  - Individual extractor testing"